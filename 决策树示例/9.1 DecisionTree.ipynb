{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  准备数据\n",
    "StumbleUpon Evergreen数据，来源于Kaggle中的一个题目StumbleUpon Evergreen Classification Challenge。\n",
    "\n",
    "StumbleUpon 是一个个性化推荐引擎，根据用户的兴趣行为给用户推荐网页，而有些网页内容是即时性（ephemeral）的，比如新闻股票网页（用户短暂感兴趣），有些网页是长久性的（evergreen）如体育，理财等（用户持续感兴趣）。现要分辨网页是ephemeral的还是evergreen的，以便向用户推荐更加准确的网页。\n",
    "\n",
    "这是一个二分类问题。\n",
    "\n",
    "查看StumbleUpon数据的详细信息：https:www.kaggle.com/c/stumbleupon/data\n",
    "\n",
    "下载StumbleUpon数据，train.tsv和test.tsv。\n",
    "\n",
    "分析train.tsv的字段：\n",
    "\n",
    "- 0~2列忽略，url，urlid对网站是否evergreen关系不大\n",
    "- 第3列，categorical features分类特征，网页分类如：business，health, sports……\n",
    "- 第4~25列，numerical features数值特征，有关此网页的数值特征，例如链接的数目，图片的比例等\n",
    "- 第26列，label分类标签，1表示evergreen（用户长久感兴趣的网页），0表示non-evergreen（用户短暂感兴趣的网页）\n",
    "\n",
    "test.tsv没有第26列的label分类标签，其余和test.tsv相同\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始导入数据...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\"url\"\\t\"urlid\"\\t\"boilerplate\"\\t\"alchemy_category\"\\t\"alchemy_category_score\"\\t\"avglinksize\"\\t\"commonlinkratio_1\"\\t\"commonlinkratio_2\"\\t\"commonlinkratio_3\"\\t\"commonlinkratio_4\"\\t\"compression_ratio\"\\t\"embed_ratio\"\\t\"framebased\"\\t\"frameTagRatio\"\\t\"hasDomainLink\"\\t\"html_ratio\"\\t\"image_ratio\"\\t\"is_news\"\\t\"lengthyLinkDomain\"\\t\"linkwordscore\"\\t\"news_front_page\"\\t\"non_markup_alphanum_characters\"\\t\"numberOfLinks\"\\t\"numwords_in_url\"\\t\"parametrizedLinkRatio\"\\t\"spelling_errors_ratio\"\\t\"label\"',\n",
       " '\"http://www.bloomberg.com/news/2010-12-23/ibm-predicts-holographic-calls-air-breathing-batteries-by-2015.html\"\\t\"4042\"\\t\"{\"\"title\"\":\"\"IBM Sees Holographic Calls Air Breathing Batteries ibm sees holographic calls, air-breathing batteries\"\",\"\"body\"\":\"\"A sign stands outside the International Business Machines Corp IBM Almaden Research Center campus in San Jose California Photographer Tony Avelar Bloomberg Buildings stand at the International Business Machines Corp IBM Almaden Research Center campus in the Santa Teresa Hills of San Jose California Photographer Tony Avelar Bloomberg By 2015 your mobile phone will project a 3 D image of anyone who calls and your laptop will be powered by kinetic energy At least that s what International Business Machines Corp sees in its crystal ball The predictions are part of an annual tradition for the Armonk New York based company which surveys its 3 000 researchers to find five ideas expected to take root in the next five years IBM the world s largest provider of computer services looks to Silicon Valley for input gleaning many ideas from its Almaden research center in San Jose California Holographic conversations projected from mobile phones lead this year s list The predictions also include air breathing batteries computer programs that can tell when and where traffic jams will take place environmental information generated by sensors in cars and phones and cities powered by the heat thrown off by computer servers These are all stretch goals and that s good said Paul Saffo managing director of foresight at the investment advisory firm Discern in San Francisco In an era when pessimism is the new black a little dose of technological optimism is not a bad thing For IBM it s not just idle speculation The company is one of the few big corporations investing in long range research projects and it counts on innovation to fuel growth Saffo said Not all of its predictions pan out though IBM was overly optimistic about the spread of speech technology for instance When the ideas do lead to products they can have broad implications for society as well as IBM s bottom line he said Research Spending They have continued to do research when all the other grand research organizations are gone said Saffo who is also a consulting associate professor at Stanford University IBM invested 5 8 billion in research and development last year 6 1 percent of revenue While that s down from about 10 percent in the early 1990s the company spends a bigger share on research than its computing rivals Hewlett Packard Co the top maker of personal computers spent 2 4 percent last year At Almaden scientists work on projects that don t always fit in with IBM s computer business The lab s research includes efforts to develop an electric car battery that runs 500 miles on one charge a filtration system for desalination and a program that shows changes in geographic data IBM rose 9 cents to 146 04 at 11 02 a m in New York Stock Exchange composite trading The stock had gained 11 percent this year before today Citizen Science The list is meant to give a window into the company s innovation engine said Josephine Cheng a vice president at IBM s Almaden lab All this demonstrates a real culture of innovation at IBM and willingness to devote itself to solving some of the world s biggest problems she said Many of the predictions are based on projects that IBM has in the works One of this year s ideas that sensors in cars wallets and personal devices will give scientists better data about the environment is an expansion of the company s citizen science initiative Earlier this year IBM teamed up with the California State Water Resources Control Board and the City of San Jose Environmental Services to help gather information about waterways Researchers from Almaden created an application that lets smartphone users snap photos of streams and creeks and report back on conditions The hope is that these casual observations will help local and state officials who don t have the resources to do the work themselves Traffic Predictors IBM also sees data helping shorten commutes in the next five years Computer programs will use algorithms and real time traffic information to predict which roads will have backups and how to avoid getting stuck Batteries may last 10 times longer in 2015 than today IBM says Rather than using the current lithium ion technology new models could rely on energy dense metals that only need to interact with the air to recharge Some electronic devices might ditch batteries altogether and use something similar to kinetic wristwatches which only need to be shaken to generate a charge The final prediction involves recycling the heat generated by computers and data centers Almost half of the power used by data centers is currently spent keeping the computers cool IBM scientists say it would be better to harness that heat to warm houses and offices In IBM s first list of predictions compiled at the end of 2006 researchers said instantaneous speech translation would become the norm That hasn t happened yet While some programs can quickly translate electronic documents and instant messages and other apps can perform limited speech translation there s nothing widely available that acts like the universal translator in Star Trek Second Life The company also predicted that online immersive environments such as Second Life would become more widespread While immersive video games are as popular as ever Second Life s growth has slowed Internet users are flocking instead to the more 2 D environments of Facebook Inc and Twitter Inc Meanwhile a 2007 prediction that mobile phones will act as a wallet ticket broker concierge bank and shopping assistant is coming true thanks to the explosion of smartphone applications Consumers can pay bills through their banking apps buy movie tickets and get instant feedback on potential purchases all with a few taps on their phones The nice thing about the list is that it provokes thought Saffo said If everything came true they wouldn t be doing their job To contact the reporter on this story Ryan Flinn in San Francisco at rflinn bloomberg net To contact the editor responsible for this story Tom Giles at tgiles5 bloomberg net by 2015, your mobile phone will project a 3-d image of anyone who calls and your laptop will be powered by kinetic energy. at least that\\\\u2019s what international business machines corp. sees in its crystal ball.\"\",\"\"url\"\":\"\"bloomberg news 2010 12 23 ibm predicts holographic calls air breathing batteries by 2015 html\"\"}\"\\t\"business\"\\t\"0.789131\"\\t\"2.055555556\"\\t\"0.676470588\"\\t\"0.205882353\"\\t\"0.047058824\"\\t\"0.023529412\"\\t\"0.443783175\"\\t\"0\"\\t\"0\"\\t\"0.09077381\"\\t\"0\"\\t\"0.245831182\"\\t\"0.003883495\"\\t\"1\"\\t\"1\"\\t\"24\"\\t\"0\"\\t\"5424\"\\t\"170\"\\t\"8\"\\t\"0.152941176\"\\t\"0.079129575\"\\t\"0\"']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 读取train.tsv\n",
    "print(\"开始导入数据...\")\n",
    "rawDataWithHeader = sc.textFile(\"data/train.tsv\")\n",
    "## 取出前2项数据\n",
    "rawDataWithHeader.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从运行结果看出：第一项是字段名(特征名称)不是数据（要进行删除）；每一项数据以制表符”\\t”分隔；每个字段前后都有双引号“””分隔。除此之外，在train.tsv表中有些字段有缺失值用”?”表示。\n",
    "\n",
    "针对以上问题对train.tsv进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始导入数据...\n",
      "共有：7395项数据\n"
     ]
    }
   ],
   "source": [
    "## 读取train.tsv\n",
    "print(\"开始导入数据...\")\n",
    "rawDataWithHeader = sc.textFile(\"data/train.tsv\")\n",
    "## 取第一项数据\n",
    "header = rawDataWithHeader.first()\n",
    "## 剔除字段名（特征名）行，取数据行\n",
    "rawData = rawDataWithHeader.filter(lambda x:x!=header)\n",
    "## 将双引号\"替换为空字符（剔除双引号）\n",
    "rData = rawData.map(lambda x:x.replace(\"\\\"\",\"\"))\n",
    "## 以制表符分割每一行\n",
    "lines = rData.map(lambda x: x.split(\"\\t\"))\n",
    "print(\"共有：\"+str(lines.count())+\"项数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business',\n",
       " '0.789131',\n",
       " '2.055555556',\n",
       " '0.676470588',\n",
       " '0.205882353',\n",
       " '0.047058824',\n",
       " '0.023529412',\n",
       " '0.443783175',\n",
       " '0',\n",
       " '0',\n",
       " '0.09077381',\n",
       " '0',\n",
       " '0.245831182',\n",
       " '0.003883495',\n",
       " '1',\n",
       " '1',\n",
       " '24',\n",
       " '0',\n",
       " '5424',\n",
       " '170',\n",
       " '8',\n",
       " '0.152941176',\n",
       " '0.079129575',\n",
       " '0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~2列忽略，url，urlid对网站是否evergreen关系不大\n",
    "lines.first()[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  处理特征\n",
    "\n",
    "该数据集的第3个字段是alchemy_category网页分类，是一个离散值特征，要采用OneHotEncode的方式进行编码转换为数值特征，主要过程如下：\n",
    "\n",
    "1. 创建categoriesMap字典，key为网页类别名，value为数字（网页类别名的索引值），每个类别名对应一个索引值\n",
    "2. 根据categoriesMap字典查询每个alchemy_category特征值对应的索引值，例如business的索引值categoryIdx为2\n",
    "3. 根据categoryIdx=2，以OneHotEncodeer的方式转换为一个列表categoryFeatures List，该列表长度为14（统计所有网页类别），categoryIdx=2对应的列表为[0,0,1,0,0,0,0,0,0,0,0,0,0,0]。\n",
    "\n",
    "建立categoriesMap网页分类字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoriesMap = lines.map(lambda x: x[3]).distinct().zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，lines.map()表示处理之前读取的数据的每一行，.map(lambda fields: fileds[3])表示读取第3个字段，.distinct()保留不重复数据，.zipWithIndex()将第3个字段中不重复的数据进行编号，.collectAsMap()转换为dict字典格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': 0,\n",
       " 'recreation': 1,\n",
       " 'health': 2,\n",
       " 'sports': 3,\n",
       " '?': 4,\n",
       " 'arts_entertainment': 5,\n",
       " 'science_technology': 6,\n",
       " 'gaming': 7,\n",
       " 'culture_politics': 8,\n",
       " 'computer_internet': 9,\n",
       " 'law_crime': 10,\n",
       " 'religion': 11,\n",
       " 'weather': 12,\n",
       " 'unknown': 13}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoriesMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将每个alchemy_category网页分类特征值转化为列表categoryFeatures List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "categoryIndex = categoriesMap[lines.first()[3]]\n",
    "OneHot = np.zeros(len(categoriesMap))\n",
    "OneHot[categoryIndex]=1\n",
    "print(OneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于第4~25字段的数值特征，要转换为数值，用float函数将字符串转换为数值，同时简单处理缺失值”?”为0.\n",
    "\n",
    "整个处理特征的过程可以封装成一个函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert(v):\n",
    "    \"\"\"处理数值特征的转换函数\"\"\"\n",
    "    return (0 if v==\"?\" else float(v))\n",
    "\n",
    "def process_features(line, categoriesMap, featureEnd):\n",
    "    \"\"\"处理特征，line为字段行，categoriesMap为网页分类字典，featureEnd为特征结束位置，此例为25\"\"\"\n",
    "    ## 处理alchemy_category网页分类特征\n",
    "    categoryIdx = categoriesMap[line[3]]\n",
    "    OneHot = np.zeros(len(categoriesMap))\n",
    "    OneHot[categoryIdx] = 1\n",
    "    ## 处理数值特征\n",
    "    numericalFeatures = [convert(value) for value in line[4:featureEnd]]\n",
    "    # 返回拼接的总特征列表\n",
    "    return np.concatenate((OneHot, numericalFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、处理label分类标签\n",
    "\n",
    "定义一个函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(line):\n",
    "    return float(line[-1])  # 最后一个字段为类别标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、构建模型所需数据格式\n",
    "\n",
    "Spark Mllib分类任务支持的数据类型为LabeledPoint格式，LabeledPoint数据由标签label和特征feature组成。构建LabeledPoint数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "labelpointRDD = lines.map(lambda r: LabeledPoint(process_label(r), process_features(r,categoriesMap, len(r)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelpointRDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、划分训练集、验证集以及测试集\n",
    "\n",
    "按照7:1:2的比例划分训练集、验证集以及测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本个数：5137验证集样本个数：791测试集样本个数：1467\n"
     ]
    }
   ],
   "source": [
    "## 划分训练集、验证集和测试集\n",
    "(trainData, validationData, testData) = labelpointRDD.randomSplit([7,1,2])\n",
    "print(\"训练集样本个数：\"+str(trainData.count()) + \"验证集样本个数：\"+str(validationData.count())+ \"测试集样本个数：\"+str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[42] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据暂存到内存中，加快后续运算效率\n",
    "trainData.persist()\n",
    "validationData.persist()\n",
    "testData.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 训练模型\n",
    "选择Spark MLlib中的决策树DecisionTree模块中的trainClassifier方法进行训练并建立模型：\n",
    "\n",
    "DecisionTree.trainClassifier(input, numClasses, categoricalFeaturesInfo, impurity,maxDepth,maxBins)\n",
    "参数说明如下：\n",
    "\n",
    "- (1) input：输入的训练数据，数据格式为LabeledPoint数据\n",
    "- (2) numClasses：指定分类数目\n",
    "- (3) categoricalFeaturesInfo：设置分类特征字段信息，本例采用OneHot编码处理分类特征字段，故这里设置为空字典dict()\n",
    "- (4) impurity：决策树的impurity评估方法（划分的度量选择）：gini基尼系数，entropy熵\n",
    "- (5) maxDepth：决策树最大深度\n",
    "- (6) maxBins：决策树每个节点的最大分支数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree\n",
    "model = DecisionTree.trainClassifier(trainData, numClasses=2,categoricalFeaturesInfo={}, impurity=\"entropy\", maxDepth=5,maxBins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7   评估模型\n",
    "使用AUC(Area under the Curve of ROC)来对模型进行评估，接收者操作特征(Receiver Operating Characteristic , ROC)曲线是一种比较分类器模型有用的可视化工具。\n",
    "\n",
    "ROC曲线显示了给定模型的真正例率(TPR=TP/P)(纵轴)和假正例率(FPR=FP/N)(横轴)之间的权衡。TPR的增加以FPR的增加为代价。ROC曲线下方的面积是模型准确率的度量：AUC\n",
    "\n",
    "- AUC=1：预测准确率100%\n",
    "- 0.5 < AUC <1：优于随机猜测，具有预测意义\n",
    "- AUC=0.5: 与随机猜测一样，没有预测意义\n",
    "- AUC<0.5: 比随机预测还差\n",
    "\n",
    "Spark Mllib提供了BinaryClassificationMetrics计算AUC的方法。\n",
    "\n",
    "首先创建predict_real列表，列表的每个元素为一个元组(predict,real)，其中predict为预测结果，real为实际标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 0.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 创建predict_real列表\n",
    "predict = model.predict(validationData.map(lambda p:p.features))\n",
    "predict_real = predict.zip(validationData.map(lambda p: p.label))\n",
    "predict_real.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着使用BinaryClassificationMetrics计算AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.6324127403568633\n"
     ]
    }
   ],
   "source": [
    "## 使用BinaryClassificationMetrics计算AUC\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(predict_real)\n",
    "print(\"AUC=\"+str(metrics.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8  模型参数选择\n",
    "DecisionTree的参数impurity,maxDepth,maxBins会影响模型的准确率及训练的时间，下面对不同模型参数取值进行测试评估。\n",
    "\n",
    "创建trainEvaluateModel函数包含训练与评估功能，并计算训练评估的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 创建trainEvaluateModel函数包含训练与评估功能，并计算训练评估的时间。\n",
    "from time import time\n",
    "\n",
    "def trainEvaluateModel(trainData, validationData, impurityParm, maxDepthParm, maxBinsParm):\n",
    "    startTime = time()\n",
    "    ## 创建并训练模型\n",
    "    model = DecisionTree.trainClassifier(trainData, numClasses=2,categoricalFeaturesInfo={}, \n",
    "                                         impurity=impurityParm, maxDepth=maxDepthParm,maxBins=maxBinsParm)\n",
    "    ## 计算AUC\n",
    "    predict = model.predict(validationData.map(lambda p:p.features))\n",
    "    predict_real = predict.zip(validationData.map(lambda p: p.label))\n",
    "    metrics = BinaryClassificationMetrics(predict_real)\n",
    "    AUC = metrics.areaUnderROC\n",
    "    duration = time() - startTime   # 持续时间\n",
    "#     print(\"训练评估：参数\"+\"impurity=\"+str(impurityParm) + \n",
    "#          \"   maxDepth=\"+str(maxDepthParm)+\"   maxBins=\"+str(maxBinsParm)+\"\\n\"+\n",
    "#          \"===>消耗时间=\"+str(duration)+\"   结果AUC=\"+str(AUC))\n",
    "    return AUC, duration, impurityParm, maxDepthParm, maxBinsParm, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、评估impurity参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=10\n",
      "===>消耗时间=1.999284267425537   结果AUC=0.6431558423233321\n",
      "训练评估：参数impurity=entropy   maxDepth=10   maxBins=10\n",
      "===>消耗时间=1.731438159942627   结果AUC=0.6598188745077415\n"
     ]
    }
   ],
   "source": [
    "## 评估impurity参数\n",
    "impurityList=[\"gini\",\"entropy\"]\n",
    "maxDepthList = [10]\n",
    "maxBinsList = [10]\n",
    "\n",
    "## 返回结果存放至metries中\n",
    "metrics = [trainEvaluateModel(trainData, validationData, impurity, maxDepth, maxBins)\n",
    "          for impurity in impurityList\n",
    "          for maxDepth in maxDepthList\n",
    "          for maxBins in maxBinsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6431558423233321, 1.999284267425537, 'gini', 10, 10, DecisionTreeModel classifier of depth 10 with 557 nodes), (0.6598188745077415, 1.731438159942627, 'entropy', 10, 10, DecisionTreeModel classifier of depth 10 with 471 nodes)]\n"
     ]
    }
   ],
   "source": [
    "# 查看metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以图表形式显示训练评估结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>duration</th>\n",
       "      <th>impurity</th>\n",
       "      <th>maxDepth</th>\n",
       "      <th>maxBins</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gini</th>\n",
       "      <td>0.643156</td>\n",
       "      <td>1.999284</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeModel classifier of depth 10 with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.659819</td>\n",
       "      <td>1.731438</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeModel classifier of depth 10 with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AUC  duration impurity  maxDepth  maxBins  \\\n",
       "gini     0.643156  1.999284     gini        10       10   \n",
       "entropy  0.659819  1.731438  entropy        10       10   \n",
       "\n",
       "                                                     model  \n",
       "gini     DecisionTreeModel classifier of depth 10 with ...  \n",
       "entropy  DecisionTreeModel classifier of depth 10 with ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "IndexList = impurityList\n",
    "df= pd.DataFrame(metrics,index=IndexList,columns=[\"AUC\",\"duration\",\"impurity\",\"maxDepth\",\"maxBins\",\"model\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、评估maxDepth参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练评估：参数impurity=gini   maxDepth=3   maxBins=10\n",
      "===>消耗时间=1.832421064376831   结果AUC=0.6098233641622945\n",
      "训练评估：参数impurity=gini   maxDepth=5   maxBins=10\n",
      "===>消耗时间=1.8724696636199951   结果AUC=0.6529112202881076\n",
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=10\n",
      "===>消耗时间=1.16658353805542   结果AUC=0.6431558423233321\n",
      "训练评估：参数impurity=gini   maxDepth=15   maxBins=10\n",
      "===>消耗时间=1.6244165897369385   结果AUC=0.6239144656669703\n",
      "训练评估：参数impurity=gini   maxDepth=20   maxBins=10\n",
      "===>消耗时间=1.8939316272735596   结果AUC=0.6245333966160832\n",
      "训练评估：参数impurity=gini   maxDepth=25   maxBins=10\n",
      "===>消耗时间=2.4340503215789795   结果AUC=0.6245333966160832\n"
     ]
    }
   ],
   "source": [
    "## 评估maxDepthList参数\n",
    "impurityList = [\"gini\"]\n",
    "maxDepthList = [3,5,10,15,20,25]\n",
    "maxBinsList = [10]\n",
    "#\n",
    "# 存放结果存放至metrics中\n",
    "metrics = [trainEvaluateModel(trainData, validationData, impurity, maxDepth, maxBins)\n",
    "          for impurity in impurityList\n",
    "          for maxDepth in maxDepthList\n",
    "          for maxBins in maxBinsList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、评估maxBins参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=3\n",
      "===>消耗时间=1.8239459991455078   结果AUC=0.6680894595738677\n",
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=5\n",
      "===>消耗时间=1.4326863288879395   结果AUC=0.6270283617891914\n",
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=10\n",
      "===>消耗时间=1.2209198474884033   结果AUC=0.6431558423233321\n",
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=15\n",
      "===>消耗时间=1.099700689315796   结果AUC=0.6381851533537719\n",
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=100\n",
      "===>消耗时间=1.400726079940796   结果AUC=0.6595911848839746\n",
      "训练评估：参数impurity=gini   maxDepth=10   maxBins=200\n",
      "===>消耗时间=1.6041264533996582   结果AUC=0.6563329784368306\n"
     ]
    }
   ],
   "source": [
    "## 评估maxBins参数\n",
    "impurityList = [\"gini\"]\n",
    "maxDepthList = [10]\n",
    "maxBinsList = [3,5,10,15,100,200]\n",
    "#\n",
    "# 存放结果存放至metrics中\n",
    "metrics = [trainEvaluateModel(trainData, validationData, impurity, maxDepth, maxBins)\n",
    "          for impurity in impurityList\n",
    "          for maxDepth in maxDepthList\n",
    "          for maxBins in maxBinsList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、网格搜索最佳参数组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数组合：impurity=entropy,  maxDepth=10,  maxBins=200\n",
      ",  结果AUC=0.6733680105699297\n"
     ]
    }
   ],
   "source": [
    "## 定义函数gridSearch网格搜索最佳参数组合\n",
    "\n",
    "def gridSearch(trainData, validationData, impurityList, maxDepthList, maxBinsList ):\n",
    "    metrics = [trainEvaluateModel(trainData, validationData, impurity, maxDepth, maxBins)\n",
    "          for impurity in impurityList\n",
    "          for maxDepth in maxDepthList\n",
    "          for maxBins in maxBinsList]\n",
    "    # 按照AUC从大到小排序，返回最大AUC的参数组合\n",
    "    sorted_metics = sorted(metrics, key=lambda k:k[0], reverse=True)\n",
    "    best_parameters = sorted_metics[0]\n",
    "    print(\"最佳参数组合：\"+\"impurity=\"+str( best_parameters[2]) + \n",
    "         \",  maxDepth=\"+str( best_parameters[3])+\",  maxBins=\"+str( best_parameters[4])+\"\\n\"+\n",
    "         \",  结果AUC=\"+str( best_parameters[0]))\n",
    "    return  best_parameters\n",
    "## 参数组合\n",
    "impurityList=[\"gini\", \"entropy\"]\n",
    "maxDepthList = [3,5,10,15,20,25]\n",
    "maxBinsList = [3,5,10,15,100,200]\n",
    "\n",
    "## 调用函数返回最佳参数组合\n",
    "best_parameters = gridSearch(trainData, validationData, impurityList, maxDepthList, maxBinsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9  判断是否过拟合以及模型预测\n",
    "### 1、判断是否过拟合\n",
    "\n",
    "前面已经得到最佳参数组合impurity=entropy, maxDepth=10, maxBins=15及相应的AUC评估。使用该最佳参数组合作用于测试数据，是否会过拟合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: AUC=0.7736970524550343\n",
      "testing: AUC=0.6274975225772675\n"
     ]
    }
   ],
   "source": [
    "## 定义模型评估函数\n",
    "def evaluateModel(model, validationData):\n",
    "    predict = model.predict(validationData.map(lambda p:p.features))\n",
    "    predict_real = predict.zip(validationData.map(lambda p: p.label))\n",
    "    metrics = BinaryClassificationMetrics(predict_real)\n",
    "    return metrics.areaUnderROC\n",
    "\n",
    "## 使用最佳参数组合impurity=entropy,  maxDepth=10,  maxBins=15训练模型\n",
    "best_model = DecisionTree.trainClassifier(trainData, numClasses=2,categoricalFeaturesInfo={}, \n",
    "                                         impurity=\"entropy\", maxDepth=10,maxBins=15)\n",
    "AUC1 = evaluateModel(best_model, trainData)\n",
    "AUC2 = evaluateModel(best_model, testData)\n",
    "print(\"training: AUC=\"+str(AUC1))\n",
    "print(\"testing: AUC=\"+str(AUC2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该模型在测试集上的准确率比训练集上的准确率差别较大，可以判定发生了过拟合。\n",
    "\n",
    "## 2、使用模型进行预测\n",
    "\n",
    "如果不考虑过拟合，依然使用上面最佳参数组合的模型对test.tsv进行预测，返回预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始导入数据...\n",
      "网址：http://www.lynnskitchenadventures.com/2009/04/homemade-enchilada-sauce.html\n",
      " ===>预测结果为: 1.0说明: 长久型(evergreen)网页\n",
      "\n",
      "网址：http://lolpics.se/18552-stun-grenade-ar\n",
      " ===>预测结果为: 0.0说明: 暂时型(ephemeral)网页\n",
      "\n",
      "网址：http://www.xcelerationfitness.com/treadmills.html\n",
      " ===>预测结果为: 0.0说明: 暂时型(ephemeral)网页\n",
      "\n",
      "网址：http://www.bloomberg.com/news/2012-02-06/syria-s-assad-deploys-tactics-of-father-to-crush-revolt-threatening-reign.html\n",
      " ===>预测结果为: 0.0说明: 暂时型(ephemeral)网页\n",
      "\n",
      "网址：http://www.wired.com/gadgetlab/2011/12/stem-turns-lemons-and-limes-into-juicy-atomizers/\n",
      " ===>预测结果为: 1.0说明: 长久型(evergreen)网页\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 使用模型进行预测\n",
    "def predictData(sc,model,categoriesMap):\n",
    "    print(\"开始导入数据...\")\n",
    "    rawDataWithHeader = sc.textFile(\"data/test.tsv\")\n",
    "    ## 取第一项数据\n",
    "    header = rawDataWithHeader.first()\n",
    "    ## 剔除字段名（特征名）行，取数据行\n",
    "    rawData = rawDataWithHeader.filter(lambda x:x!=header)\n",
    "    ## 将双引号\"替换为空字符（剔除双引号）\n",
    "    rData = rawData.map(lambda x:x.replace(\"\\\"\",\"\"))\n",
    "    ## 以制表符分割每一行\n",
    "    lines = rData.map(lambda x: x.split(\"\\t\"))\n",
    "    ## 预处理测试数据集\n",
    "    testDataRDD=lines.map(lambda r: (r[0], process_features(r, categoriesMap, len(r))))\n",
    "    DescDict={0:\"暂时型(ephemeral)网页\",\n",
    "              1:\"长久型(evergreen)网页\"}\n",
    "    ## 预测前5项数据\n",
    "    for testData in testDataRDD.take(5):\n",
    "        predictResult=model.predict(testData[1])\n",
    "        print(\"网址：\"+str(testData[0])+\"\\n\"+\" ===>预测结果为: \"+str(predictResult) + \"说明: \"+DescDict[predictResult]+\"\\n\")\n",
    "\n",
    "predictData(sc,best_model,categoriesMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 查看决策树分类规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 查看决策树分类规则\n",
    "# best_model.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "\n",
    "上述模型发生了过拟合，请给出不会过拟合的模型，并给出预测测试结果和分类规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
